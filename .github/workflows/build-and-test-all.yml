---
name: 'Build and test everything'

on:
  push:
  pull_request:
  workflow_call:
    inputs:
      branch-name:
        description: 'Checkout to a specific branch'
        required: true
        default: ''
        type: string
      runner-docker-image-name:
        description: 'Image name to be used for running all jobs'
        required: false
        default: ''
        type: string
  schedule:
    - cron: '0 22 * * 3'

permissions: # least privileges, see https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#permissions
  contents: read

env:
  COMPILER: clang
  CLANG_VERSION: '13'
  # github.workspace variable points to the Runner home folder. Container home folder defined below.
  REPO_HOME: '/__w/${{ github.event.repository.name }}/${{ github.event.repository.name }}'
  BUILDER_VERSION: '0.0.0-git1'
  COVERAGE: ${{ github.repository == 'PowerDNS/pdns' && 'yes' || 'no' }}
  LLVM_PROFILE_FILE: "/tmp/code-%p.profraw"
  OPTIMIZATIONS: yes
  INV_CMD: ". ${REPO_HOME}/.venv/bin/activate && inv"
  BRANCH_NAME: ${{ inputs.branch-name || github.ref_name }}

jobs:
  get-runner-container-image:
    name: generate docker runner image name
    runs-on: ubuntu-24.04
    outputs:
      id: ${{ steps.get-runner-image.outputs.image-id }}
      tag: ${{ steps.get-runner-image.outputs.tag }}
    env:
      DEFAULT_IMAGE_TAG: master # update when backporting, e.g. auth-4.9.x
      DOCKER_IMAGE: ${{ inputs.runner-docker-image-name || 'base-pdns-ci-image/debian-12-pdns-base' }}
    steps:
      - id: get-runner-image
        run: |
          echo "image-id=ghcr.io/powerdns/$DOCKER_IMAGE" >> "$GITHUB_OUTPUT"
          echo "tag=$DEFAULT_IMAGE_TAG" >> "$GITHUB_OUTPUT"

  build-dnsdist:
    name: build dnsdist
    if: ${{ !github.event.schedule || vars.SCHEDULED_JOBS_BUILD_AND_TEST_ALL }}
    runs-on: ${{ ( vars.REPOSITORY_USE_UBICLOUD == '1' ) && 'ubicloud-standard-4-ubuntu-2404' || 'ubuntu-24.04' }}
    needs: get-runner-container-image
    strategy:
      matrix:
        builder: [autotools, meson]
        sanitizers: [asan+ubsan, tsan]
        features: [least, full]
        exclude:
          - sanitizers: tsan
            features: least
      fail-fast: false
    container:
      image: "${{ needs.get-runner-container-image.outputs.id }}:${{ needs.get-runner-container-image.outputs.tag }}"
      env:
        SANITIZERS: ${{ matrix.sanitizers }}
        UBSAN_OPTIONS: "print_stacktrace=1:halt_on_error=1:suppressions=${{ env.REPO_HOME }}/build-scripts/UBSan.supp"
        UNIT_TESTS: yes
        FUZZING_TARGETS: yes
      options: --sysctl net.ipv6.conf.all.disable_ipv6=0
    defaults:
      run:
        working-directory: ./pdns/dnsdistdist/dnsdist-${{ env.BUILDER_VERSION }}
    env:
      CLANG_VERSION: ${{ contains(needs.get-runner-container-image.outputs.id, 'debian-11') && '13' || '19' }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 5
          submodules: recursive
          ref: ${{ inputs.branch-name }}
          persist-credentials: false
      - name: get timestamp for cache
        id: get-stamp
        run: |
          echo "stamp=$(/bin/date +%s)" >> "$GITHUB_OUTPUT"
        shell: bash
        working-directory: .
      - run: mkdir -p ~/.ccache
        working-directory: .
      - name: let GitHub cache our ccache data
        uses: actions/cache@v4
        with:
          path: ~/.ccache
          key: dnsdist-${{ matrix.features }}-${{ matrix.sanitizers }}-${{ matrix.builder}}-ccache-${{ steps.get-stamp.outputs.stamp }}
          restore-keys: dnsdist-${{ matrix.features }}-${{ matrix.sanitizers }}-${{ matrix.builder}}-ccache-
      - name: install pip build dependencies
        run: |
          python3 -m venv ${REPO_HOME}/.venv
          . ${REPO_HOME}/.venv/bin/activate && pip install -r ${REPO_HOME}/meson/requirements.txt
        working-directory: .
      - run: ${{ env.INV_CMD }} install-dnsdist-build-deps $([ "$(. /etc/os-release && echo $VERSION_CODENAME)" = "bullseye" ] && echo "--skipXDP=True")
        working-directory: .
      - run: ${{ env.INV_CMD }} install-clang
        working-directory: .
      - run: ${{ env.INV_CMD }} install-lld-linker-if-needed
        working-directory: ./pdns/dnsdistdist/
      - run: ${{ env.INV_CMD }} ci-install-rust ${REPO_HOME}
        working-directory: ./pdns/dnsdistdist/
      - run: ${{ env.INV_CMD }} ci-build-and-install-quiche ${REPO_HOME}
        working-directory: ./pdns/dnsdistdist/
      - run: ${{ env.INV_CMD }} ci-autoconf
        if: ${{ matrix.builder == 'autotools' }}
        working-directory: ./pdns/dnsdistdist/
      - run: ${{ env.INV_CMD }} ci-dnsdist-configure ${{ matrix.features }} ${{ matrix.builder }} dnsdist-${{ env.BUILDER_VERSION }}
        working-directory: ./pdns/dnsdistdist/
      - run: ${{ env.INV_CMD }} ci-make-distdir
        if: ${{ matrix.builder == 'autotools' }}
        working-directory: ./pdns/dnsdistdist/
      - run: ${{ env.INV_CMD }} ci-dnsdist-configure ${{ matrix.features }} ${{ matrix.builder }} dnsdist-${{ env.BUILDER_VERSION }}
        if: ${{ matrix.builder == 'autotools' }}
      - run: ${{ env.INV_CMD }} ci-dnsdist-make-bear ${{ matrix.builder }}
      - run: ${{ env.INV_CMD }} ci-dnsdist-run-unit-tests ${{ matrix.builder }}
      - run: ${{ env.INV_CMD }} generate-coverage-info ./testrunner $GITHUB_WORKSPACE
        if: ${{ env.COVERAGE == 'yes' && matrix.sanitizers != 'tsan' && matrix.builder == 'meson'}}
      - name: Coveralls Parallel dnsdist unit
        if: ${{ env.COVERAGE == 'yes' && matrix.sanitizers != 'tsan' && matrix.builder == 'meson' }}
        uses: coverallsapp/github-action@648a8eb78e6d50909eff900e4ec85cab4524a45b
        with:
          flag-name: dnsdist-unit-${{ matrix.features }}-${{ matrix.sanitizers }}
          path-to-lcov: $GITHUB_WORKSPACE/coverage.lcov
          parallel: true
          allow-empty: true
          fail-on-error: false
      - run: ${{ env.INV_CMD }} ci-dnsdist-install ${{ matrix.builder == 'meson' && '--meson' || '' }}
      - run: ccache -s
      - name: Prepare binaries folder
        if: ${{ matrix.builder == 'meson' }}
        run: |
          echo "normalized-branch-name=$BRANCH_NAME" | tr "/" "-" >> "$GITHUB_ENV"
          mkdir -p /opt/dnsdist/bin
          for i in $(find . -maxdepth 1 -type f -executable); do cp ${i} /opt/dnsdist/bin/; done
      - name: Store the binaries
        if: ${{ matrix.builder == 'meson' }}
        uses: actions/upload-artifact@v4 # this takes 30 seconds, maybe we want to tar
        with:
          name: dnsdist-${{ matrix.features }}-${{ matrix.sanitizers }}-${{ matrix.builder}}-${{ env.normalized-branch-name }}
          path: /opt/dnsdist
          retention-days: 1

  test-dnsdist-regression:
    needs:
      - build-dnsdist
      - get-runner-container-image
    runs-on: ubuntu-24.04
    strategy:
      matrix:
        sanitizers: [asan+ubsan, tsan]
      fail-fast: false
    container:
      image: "${{ needs.get-runner-container-image.outputs.id }}:${{ needs.get-runner-container-image.outputs.tag }}"
      env:
        UBSAN_OPTIONS: "print_stacktrace=1:halt_on_error=1:suppressions=${{ env.REPO_HOME }}/build-scripts/UBSan.supp"
        # Disabling (intercept_send=0) the custom send wrappers for ASAN and TSAN because they cause the tools to report a race that doesn't exist on actual implementations of send(), see https://github.com/google/sanitizers/issues/1498
        ASAN_OPTIONS: intercept_send=0
        LSAN_OPTIONS: "suppressions=${{ env.REPO_HOME }}/pdns/dnsdistdist/dnsdist-lsan.supp"
        TSAN_OPTIONS: "halt_on_error=1:intercept_send=0:suppressions=${{ env.REPO_HOME }}/pdns/dnsdistdist/dnsdist-tsan.supp"
        # IncludeDir tests are disabled because of a weird interaction between TSAN and these tests which ever only happens on GH actions
        SKIP_INCLUDEDIR_TESTS: yes
        SANITIZERS: ${{ matrix.sanitizers }}
        COVERAGE: no
      options: --sysctl net.ipv6.conf.all.disable_ipv6=0 --privileged
    env:
      CLANG_VERSION: ${{ contains(needs.get-runner-container-image.outputs.id, 'debian-11') && '13' || '19' }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 5
          submodules: recursive
          ref: ${{ inputs.branch-name }}
          persist-credentials: false
      - run: echo "normalized-branch-name=$BRANCH_NAME" | tr "/" "-" >> "$GITHUB_ENV"
      - name: Fetch the binaries
        uses: actions/download-artifact@v4
        with:
          name: dnsdist-full-${{ matrix.sanitizers }}-meson-${{ env.normalized-branch-name }}
          path: /opt/dnsdist
      - name: install pip build dependencies
        run: |
          python3 -m venv ${REPO_HOME}/.venv
          . ${REPO_HOME}/.venv/bin/activate && pip install -r ${REPO_HOME}/meson/requirements.txt
      - run: ${{ env.INV_CMD }} install-clang-runtime
      - run: ${{ env.INV_CMD }} install-dnsdist-test-deps $([ "$(. /etc/os-release && echo $VERSION_CODENAME)" = "bullseye" ] && echo "--skipXDP=True")
      - run: ${{ env.INV_CMD }} test-dnsdist $([ "$(. /etc/os-release && echo $VERSION_CODENAME)" = "bullseye" ] && echo "--skipXDP=True")
      - run: ${{ env.INV_CMD }} generate-coverage-info /opt/dnsdist/bin/dnsdist $GITHUB_WORKSPACE
        if: ${{ env.COVERAGE == 'yes' && matrix.sanitizers != 'tsan' }}
      - name: Coveralls Parallel dnsdist regression
        if: ${{ env.COVERAGE == 'yes' && matrix.sanitizers != 'tsan' }}
        uses: coverallsapp/github-action@648a8eb78e6d50909eff900e4ec85cab4524a45b
        with:
          flag-name: dnsdist-regression-full-${{ matrix.sanitizers }}
          path-to-lcov: $GITHUB_WORKSPACE/coverage.lcov
          parallel: true
          allow-empty: true
          fail-on-error: false

  collect:
    needs:
      - build-dnsdist
      - test-dnsdist-regression
    if: success() || failure()
    runs-on: ubuntu-24.04
    env:
      NEEDS: ${{ toJSON(needs) }}
    steps:
      - name: Coveralls Parallel Finished
        if: ${{ env.COVERAGE == 'yes' }}
        uses: coverallsapp/github-action@648a8eb78e6d50909eff900e4ec85cab4524a45b
        with:
          parallel-finished: true
          fail-on-error: false
      - name: Install jq and jc
        run: "sudo apt-get update && sudo apt-get install jq jc"
      - name: Fail job if any of the previous jobs failed
        run: "for i in `echo ${NEEDS} | jq -r '.[].result'`; do if [[ $i == 'failure' ]]; then echo ${NEEDS}; exit 1; fi; done;"
      - uses: actions/checkout@v4
        with:
          fetch-depth: 5
          submodules: recursive
          ref: ${{ inputs.branch-name }}
          persist-credentials: false
      - name: Get list of jobs in the workflow
        run: "cat .github/workflows/build-and-test-all.yml | jc --yaml | jq -rS '.[].jobs | keys | .[]' | grep -vE 'collect|get-runner-container-image' | tee /tmp/workflow-jobs-list.yml"
      - name: Get list of prerequisite jobs
        run: "echo ${NEEDS} | jq -rS 'keys | .[]' | tee /tmp/workflow-needs-list.yml"
      - name: Fail if there is a job missing on the needs list
        run: "if ! diff -q /tmp/workflow-jobs-list.yml /tmp/workflow-needs-list.yml; then exit 1; fi"

# FIXME: if we can make upload/download-artifact fasts, running unit tests outside of build can let regression tests start earlier
